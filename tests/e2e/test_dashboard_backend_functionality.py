"""
E2E Tests for Dashboard Backend Functionality

Tests the core functionality that the dashboard relies on:
- Real dYdX connection capabilities
- Streaming data collection and processing
- Performance metrics tracking
- Autonomous operation validation
- Data quality and completeness

These tests ensure the dashboard will work with real data by testing
the underlying systems, not the UI components themselves.
"""

import pytest
import asyncio
import time
from typing import Dict, Any

from src.dydx_bot.connection.capabilities import ConnectionCapabilities
from src.dydx_bot.connection.client import DydxClient


class TestDashboardBackendFunctionality:
    """Test the core functionality that powers the dashboard"""
    
    @pytest.mark.asyncio
    @pytest.mark.timeout(60)
    async def test_autonomous_connection_functionality(self):
        """
        E2E test: Verify autonomous connection works for dashboard
        
        This tests the core connection functionality that the dashboard displays:
        - Connection establishment without human intervention
        - Metrics collection during connection
        - Error handling and reporting
        """
        capabilities = ConnectionCapabilities()
        
        try:
            # Test autonomous connection - core dashboard functionality
            result = await capabilities.demonstrate_autonomous_connection()
            
            # Verify dashboard will have connection data to display
            assert result["status"] == "connected"
            assert result["autonomous"] is True
            assert result["human_intervention_required"] is False
            assert "connection_time_ms" in result
            assert result["connection_time_ms"] > 0
            
            # Verify metrics are being tracked for dashboard display
            assert capabilities.metrics.connection_established is True
            assert capabilities.metrics.connection_start_time is not None
            assert capabilities.metrics.uptime_seconds >= 0
            
        finally:
            await capabilities.cleanup()
    
    @pytest.mark.asyncio
    @pytest.mark.timeout(90)
    async def test_streaming_data_collection_for_dashboard(self):
        """
        E2E test: Verify real streaming data collection works
        
        Tests the data collection functionality that feeds the dashboard:
        - WebSocket data streaming
        - Multiple channel subscriptions
        - Real-time data capture
        - Data structure validation
        """
        capabilities = ConnectionCapabilities()
        
        try:
            # Establish connection first
            conn_result = await capabilities.demonstrate_autonomous_connection()
            assert conn_result["status"] == "connected"
            
            # Test streaming capabilities - core dashboard data source
            streaming_result = await capabilities.demonstrate_streaming_capabilities()
            
            # Verify dashboard will have subscription data
            assert streaming_result["streaming_active"] is True
            assert streaming_result["autonomous_subscriptions"] is True
            assert len(streaming_result["subscriptions"]) > 0
            assert "thread_id" in streaming_result
            
            # Wait for real data to flow
            await asyncio.sleep(10)
            
            # Verify dashboard will have real market data to display
            report = capabilities.get_autonomous_capabilities_report()
            streaming_caps = report["streaming_capabilities"]
            
            # Check that data is flowing for dashboard display
            assert streaming_caps["active_subscriptions"] > 0
            
            # Verify at least some data streams are working
            data_counts = streaming_caps["data_counts"]
            total_messages = sum(data_counts.values())
            assert total_messages > 0, "No streaming data received for dashboard"
            
        finally:
            await capabilities.cleanup()
    
    @pytest.mark.asyncio
    @pytest.mark.timeout(120)
    async def test_performance_metrics_for_dashboard(self):
        """
        E2E test: Verify performance metrics collection works
        
        Tests the performance monitoring that the dashboard displays:
        - Message processing latency tracking
        - Throughput measurements
        - Error rate monitoring
        - 25ms liquidation requirement validation
        """
        capabilities = ConnectionCapabilities()
        
        try:
            # Connect and start streaming
            conn_result = await capabilities.demonstrate_autonomous_connection()
            assert conn_result["status"] == "connected"
            
            streaming_result = await capabilities.demonstrate_streaming_capabilities()
            assert streaming_result["streaming_active"] is True
            
            # Let data flow to collect performance metrics
            await asyncio.sleep(15)
            
            # Get performance metrics that dashboard will display
            report = capabilities.get_autonomous_capabilities_report()
            perf_metrics = report["performance_metrics"]
            
            # Verify dashboard will have performance data
            assert "avg_processing_time_ms" in perf_metrics
            assert "max_processing_time_ms" in perf_metrics
            assert "latency_violations" in perf_metrics
            assert "meets_25ms_requirement" in perf_metrics
            assert "liquidation_ready" in perf_metrics
            
            # Verify meaningful performance data for dashboard
            if capabilities.metrics.total_messages_received > 0:
                assert perf_metrics["avg_processing_time_ms"] >= 0
                assert perf_metrics["max_processing_time_ms"] >= 0
                
                # Critical: Verify liquidation performance requirement
                assert perf_metrics["avg_processing_time_ms"] < 100, \
                    f"Processing too slow: {perf_metrics['avg_processing_time_ms']}ms"
            
        finally:
            await capabilities.cleanup()
    
    @pytest.mark.asyncio
    @pytest.mark.timeout(90)
    async def test_real_market_data_quality_for_dashboard(self):
        """
        E2E test: Verify real market data quality for dashboard display
        
        Tests that the data the dashboard will show is valid:
        - Market data structure validation
        - Orderbook data completeness
        - Trade data format verification
        - Candle data accuracy
        """
        capabilities = ConnectionCapabilities()
        
        try:
            # Connect and subscribe to get real data
            conn_result = await capabilities.demonstrate_autonomous_connection()
            assert conn_result["status"] == "connected"
            
            streaming_result = await capabilities.demonstrate_streaming_capabilities()
            assert streaming_result["streaming_active"] is True
            
            # Wait for real market data
            await asyncio.sleep(12)
            
            # Verify dashboard will have quality market data
            streaming_data = capabilities.streaming_data
            
            # Check market data quality for dashboard
            if streaming_data.latest_market:
                market_data = streaming_data.latest_market
                assert "channel" in market_data
                assert market_data["channel"] == "v4_markets"
                assert "contents" in market_data or "data" in market_data
            
            # Check orderbook data quality for dashboard
            if streaming_data.latest_orderbook:
                orderbook_data = streaming_data.latest_orderbook
                assert "channel" in orderbook_data
                assert orderbook_data["channel"] == "v4_orderbook"
                
            # Check trade data quality for dashboard
            if streaming_data.latest_trade:
                trade_data = streaming_data.latest_trade
                assert "channel" in trade_data
                assert trade_data["channel"] == "v4_trades"
            
            # Check candle data quality for dashboard
            if streaming_data.latest_candle:
                candle_data = streaming_data.latest_candle
                assert "channel" in candle_data
                assert "v4_candles" in candle_data["channel"]
            
            # Verify dashboard will have subscription tracking
            assert len(streaming_data.active_subscriptions) > 0
            
        finally:
            await capabilities.cleanup()
    
    @pytest.mark.asyncio
    @pytest.mark.timeout(120)
    async def test_autonomous_operation_report_for_dashboard(self):
        """
        E2E test: Verify comprehensive autonomous operation reporting
        
        Tests the complete report generation that feeds dashboard displays:
        - All metrics categories
        - Sniper readiness assessment
        - Test coverage reporting
        - Real-time status updates
        """
        capabilities = ConnectionCapabilities()
        
        try:
            # Full autonomous operation cycle
            conn_result = await capabilities.demonstrate_autonomous_connection()
            assert conn_result["status"] == "connected"
            
            streaming_result = await capabilities.demonstrate_streaming_capabilities()
            assert streaming_result["streaming_active"] is True
            
            # Allow time for complete data collection
            await asyncio.sleep(15)
            
            # Get comprehensive report for dashboard
            report = capabilities.get_autonomous_capabilities_report()
            
            # Verify all dashboard sections will have data
            assert "layer" in report
            assert "autonomous_operation" in report
            assert "connection_metrics" in report
            assert "performance_metrics" in report
            assert "streaming_capabilities" in report
            assert "sniper_readiness" in report
            assert "test_coverage" in report
            
            # Verify autonomous operation indicators for dashboard
            auto_op = report["autonomous_operation"]
            assert auto_op["protocol_first"] is True
            assert auto_op["dydx_v4_client_integration"] is True
            assert auto_op["self_configuring"] is True
            
            # Verify connection metrics for dashboard
            conn_metrics = report["connection_metrics"]
            assert conn_metrics["established"] is True
            assert conn_metrics["uptime_seconds"] > 0
            assert "error_rate" in conn_metrics
            
            # Verify streaming capabilities for dashboard
            streaming_caps = report["streaming_capabilities"]
            assert "active_subscriptions" in streaming_caps
            assert "data_counts" in streaming_caps
            
            # Verify sniper readiness for dashboard
            sniper_ready = report["sniper_readiness"]
            assert "connection_stable" in sniper_ready
            assert "data_flowing" in sniper_ready
            assert "latency_acceptable" in sniper_ready
            assert "ready_for_layer_3" in sniper_ready
            
        finally:
            await capabilities.cleanup()
    
    @pytest.mark.asyncio
    @pytest.mark.timeout(60)
    async def test_error_handling_for_dashboard(self):
        """
        E2E test: Verify error handling that dashboard needs to display
        
        Tests error scenarios to ensure dashboard can show:
        - Connection failures
        - Error rate tracking
        - Recovery capabilities
        - Error reporting
        """
        capabilities = ConnectionCapabilities()
        
        try:
            # Test streaming without connection to trigger error
            result = await capabilities.demonstrate_streaming_capabilities()
            
            # Verify dashboard will have error information
            assert "error" in result
            assert result["error"] == "Connection not established"
            assert "streaming_active" not in result or result["streaming_active"] is False
            
            # Now test normal connection for comparison
            capabilities = ConnectionCapabilities()  # Fresh instance
            conn_result = await capabilities.demonstrate_autonomous_connection()
            assert conn_result["status"] == "connected"
            
        finally:
            await capabilities.cleanup()
    
    @pytest.mark.asyncio 
    @pytest.mark.timeout(60)
    async def test_connection_uptime_tracking_for_dashboard(self):
        """
        E2E test: Verify uptime tracking functionality for dashboard
        
        Tests the uptime monitoring that dashboard displays:
        - Connection duration tracking
        - Uptime percentage calculation
        - Continuous operation monitoring
        """
        capabilities = ConnectionCapabilities()
        
        try:
            # Connect and track uptime
            conn_result = await capabilities.demonstrate_autonomous_connection()
            assert conn_result["status"] == "connected"
            
            # Record start time after connection
            start_time = time.time()
            
            # Let connection run to track uptime
            await asyncio.sleep(3)
            
            # Verify uptime tracking for dashboard
            report = capabilities.get_autonomous_capabilities_report()
            conn_metrics = report["connection_metrics"]
            
            assert conn_metrics["uptime_seconds"] > 0
            # More lenient check - just ensure uptime is reasonable
            assert conn_metrics["uptime_seconds"] < 60  # Should be under a minute
            
            # Verify connection is stable for dashboard display
            sniper_ready = report["sniper_readiness"]
            assert sniper_ready["connection_stable"] is True
            
        finally:
            await capabilities.cleanup()


@pytest.mark.asyncio
@pytest.mark.timeout(180)
async def test_full_dashboard_backend_integration():
    """
    Complete E2E integration test for all dashboard backend functionality
    
    This test validates the entire backend system that powers the dashboard:
    - End-to-end autonomous operation
    - Complete data flow validation
    - Performance requirements verification
    - Real-time operation capability
    """
    capabilities = ConnectionCapabilities()
    
    try:
        # Phase 1: Autonomous Connection
        print("Testing autonomous connection...")
        conn_result = await capabilities.demonstrate_autonomous_connection()
        assert conn_result["status"] == "connected"
        assert conn_result["autonomous"] is True
        
        # Phase 2: Streaming Data Setup
        print("Testing streaming capabilities...")
        streaming_result = await capabilities.demonstrate_streaming_capabilities()
        assert streaming_result["streaming_active"] is True
        assert len(streaming_result["subscriptions"]) >= 4
        
        # Phase 3: Real-Time Operation
        print("Collecting real-time data...")
        await asyncio.sleep(20)
        
        # Phase 4: Comprehensive Validation
        print("Validating complete system...")
        report = capabilities.get_autonomous_capabilities_report()
        
        # Verify all dashboard backend systems working
        assert report["autonomous_operation"]["zero_human_intervention"] is True
        assert report["connection_metrics"]["established"] is True
        assert report["connection_metrics"]["uptime_seconds"] > 0
        
        # Verify performance meets dashboard requirements
        perf_metrics = report["performance_metrics"]
        if capabilities.metrics.total_messages_received > 0:
            assert perf_metrics["liquidation_ready"] is True
            assert perf_metrics["avg_processing_time_ms"] < 50
        
        # Verify data flowing for dashboard display
        streaming_caps = report["streaming_capabilities"]
        data_counts = streaming_caps["data_counts"]
        total_data = sum(data_counts.values())
        assert total_data > 0, "No data flowing for dashboard"
        
        # Verify sniper readiness for dashboard
        sniper_ready = report["sniper_readiness"]
        assert sniper_ready["connection_stable"] is True
        assert sniper_ready["data_flowing"] is True
        
        print("âœ… All dashboard backend functionality verified!")
        
    finally:
        await capabilities.cleanup()
